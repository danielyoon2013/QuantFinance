{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Changes from default:\n",
    "\n",
    "## Effect of changes:\n",
    "N/A\n",
    "\n",
    "## 0. Overview\n",
    "\n",
    "\"Quantifying unstructured and noisy textual content is complex and involves numerous methodological issues related to the preprocessing of the data and the optimization of the algorithm used to quantify textual content. The number of **text preprocessing** that can be implemented is numerous (**lowercase**, **stemming**, **lemma-tization**, part-of-speech tagging, **stopwords removal**, **punctuation removal**, etc.) and it is not easy to identify which transformation increases (decreases) the accuracy of the classiﬁcation. The same is true for the choice of the algorithm: the large number of algorithms (Naive Bayes, SVM, logistic regression, random forest, multilayer perceptron, etc.) and the even greater number of hyperparameters for each algorithm lead to an immense number of combinations.Furthermore, the answers relative to those methodological issues strongly depend on the type of data used (informal or formal content, short or long text), on the size of the dataset (few hundreds or mil-lions of documents), on the availability of pre-classiﬁed messages (supervised or unsupervised learning), and on the type of documents (domain-speciﬁc or generic documents). While there is no one-ﬁts-all solution, we nonetheless believe that some guidance and tips can help researchers to avoid common mistakes.\"\n",
    "\n",
    "Renault, Thomas. (2020). Sentiment analysis and machine learning in finance: a comparison of methods and models on one million messages. Digital Finance. 2. 10.1007/s42521-019-00014-x. pp. 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import nltk\n",
    "#nltk.download('all-corpora')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import seaborn as sns\n",
    "\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk import word_tokenize, WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "ps = PorterStemmer()\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words_set = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load data\n",
    "Current status: Default (~5000 tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change this in testing.\n",
    "data = pd.read_csv('stock_data.csv')\n",
    "data_additional = pd.read_csv(\"additional_data_preprocessed.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sentiment</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>-1</th>\n",
       "      <td>2106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3685</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Text\n",
       "Sentiment      \n",
       "-1         2106\n",
       " 1         3685"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.groupby(by=\"Sentiment\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sentiment</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>-1</th>\n",
       "      <td>604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1363</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Text\n",
       "Sentiment      \n",
       "-1          604\n",
       " 1         1363"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_additional.groupby(by=\"Sentiment\").count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Define Clean and Lower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_and_lower(text):\n",
    "    '''\n",
    "    Input:\n",
    "        A string of messy data\n",
    "    Output:\n",
    "        A string of clean lowercase data\n",
    "    \n",
    "    1) Replacing everything that isn't a letter with a space (special characters, numbers)\n",
    "    2) Sending all text to lowercase\n",
    "    '''\n",
    "    clean_text = re.sub('[^a-zA-Z]',\" \", text)\n",
    "    clean_text = clean_text.lower()\n",
    "    return clean_text\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Define Tokenize\n",
    "Current status: Default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_data(text):\n",
    "    '''\n",
    "    Input:\n",
    "        A string of cleaned data\n",
    "    Output:\n",
    "        A list of the words in the string\n",
    "        \n",
    "    Will split the string into tokens based on what nltk package thinks is best.\n",
    "    Not sure how different it is compared to string.split(' ')\n",
    "    \n",
    "    There is also a TwitterTokenizer, maybe something to look into if we want to deal with \n",
    "        emojiis instead of replacing them with spaces.\n",
    "    '''\n",
    "    return word_tokenize(text, language='english')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Define Lemmatize and Stopword removal\n",
    "Current status: Lemmatization on\n",
    "\n",
    "Stopword removal on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemma_and_stopwords(text, remove_stop_words=False):\n",
    "    '''\n",
    "    Input:\n",
    "        List of words that have been cleaned and tokenized\n",
    "    Output:\n",
    "        A string that is supposed to represent the meaning of the original sentence, as reduced as possible\n",
    "        \n",
    "        \n",
    "    From from https://www.machinelearningplus.com/nlp/lemmatization-examples-python/\n",
    "    \"\n",
    "        Lemmatization is the process of converting a word to its base form. The difference \n",
    "            between stemming and lemmatization is, lemmatization considers the context and \n",
    "            converts the word to its meaningful base form, whereas stemming just removes the \n",
    "            last few characters, often leading to incorrect meanings and spelling errors.\n",
    "\n",
    "        For example, lemmatization would correctly identify the base form of ‘caring’ to ‘care’, \n",
    "            whereas, stemming would cutoff the ‘ing’ part and convert it to car.\n",
    "\n",
    "        ‘Caring’ -> Lemmatization -> ‘Care’\n",
    "        ‘Caring’ -> Stemming -> ‘Car’\n",
    "    \"\n",
    "    \n",
    "    \n",
    "    Since the original paper also mentioned stop words, I made sure the word is not a stop word\n",
    "    before trying to convert it. I ran it with and without the stop word and I didn't notice much difference\n",
    "    but maybe it's something to fiddle with later.\n",
    "    \n",
    "    \n",
    "    EDIT 1: The paper also mentioned 'part-of-speech' tagging, which seems to attach context to each word to help\n",
    "    convert its meaning properly. Since this seemed more complicated, and this isn't a text processing project,\n",
    "    I didn't do it. \n",
    "    However there is an entire coded example (example 3) here: https://www.machinelearningplus.com/nlp/lemmatization-examples-python/\n",
    "    so it might be quick to implement and see if it improves our classification scores after\n",
    "    \n",
    "    EDIT 2:\n",
    "    About stop words, from the paper: \n",
    "        We also ﬁnd that removing stopwords using the NLTK stopwords corpus signiﬁcantly decreases the accuracy \n",
    "        of the classiﬁcation. We believe that this result is due to the fact that the stopwords corpus from NLTK includes \n",
    "        words that could be very useful for sentiment analysis in ﬁnance such as “up”, “down”, “below” or “above”. Thus, \n",
    "        researchers should not use the standard NLTK list and should consider a more restrictive list of stopwords for \n",
    "        sentiment analysis (“a”, “an”, “the”...). This result is consistent with Saif et al (2014) who show that Naive \n",
    "        Bayes classiﬁers are more sensitive to stopword removal and that using pre-existing lists of stopwords negatively \n",
    "        impacts the performance of sentiment classiﬁcation for short-messages posted on social media.\n",
    "    '''\n",
    "    if remove_stop_words:\n",
    "        list_of_words = [lemmatizer.lemmatize(word) for word in text if(word) not in stop_words_set]\n",
    "    else:\n",
    "        list_of_words = [lemmatizer.lemmatize(word) for word in text]\n",
    "        \n",
    "    string_of_words = \" \".join(list_of_words)\n",
    "    return string_of_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Final preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_all_data(data, remove_stop_words=False):\n",
    "    '''\n",
    "    Input:\n",
    "        The column of the dataframe that contains text\n",
    "    Output:\n",
    "        A list of strings that has been through:\n",
    "            clean_data = clean_and_lower(data)\n",
    "            token_data = tokenize_data(clean_data)\n",
    "            lemma_data = lemma_and_stopwords(token_data)\n",
    "    '''\n",
    "    list_of_nice_strings = []\n",
    "    for i in data:\n",
    "        clean_string = clean_and_lower(i)\n",
    "        token_list = tokenize_data(clean_string)\n",
    "        lemma_string = lemma_and_stopwords(token_list, remove_stop_words=remove_stop_words)\n",
    "        list_of_nice_strings.append(lemma_string)\n",
    "        \n",
    "    return list_of_nice_strings\n",
    "\n",
    "# Note: Just eyeballing it, it looks like some words that are useful are being thrown out\n",
    "# I.e in fourth row (index 3) it goes from \"MNTA Over 12\" --> \"mnta\". It seems like that is a bullish tweet, but something\n",
    "# is throwing away the \"over\".\n",
    "# EDIT: I just tried without \"stop words\" and it recovered the \"Over\"... Best to try both\n",
    "\n",
    "\n",
    "# Preprocess both test and original data\n",
    "remove_stop_words = False\n",
    "clean_data = prep_all_data(data['Text'],remove_stop_words)\n",
    "clean_data_additional = prep_all_data(data_additional['Text'],remove_stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data len :  5791\n",
      "test data len  :  1967\n"
     ]
    }
   ],
   "source": [
    "print(\"train data len : \", len(clean_data))\n",
    "print(\"test data len  : \", len(clean_data_additional))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Vectorization\n",
    "Current status:\n",
    "\n",
    "Vectorization: CountVectorizer\n",
    "\n",
    "n-grams: 1 and 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_num(clean_data):\n",
    "    '''\n",
    "    Input: \n",
    "        cleaned list of strings\n",
    "    Output:\n",
    "        Numerical vector representation [0's and 1's]\n",
    "    \n",
    "    From: https://scikit-learn.org/stable/modules/feature_extraction.html#text-feature-extraction\n",
    "    More info: https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html\n",
    "    \n",
    "    Text Analysis is a major application field for machine learning algorithms. However,\n",
    "        the raw data, a sequence of symbols cannot be fed directly to the algorithms \n",
    "        themselves as most of them expect numerical feature vectors with a fixed size \n",
    "        rather than the raw text documents with variable length.\n",
    "    ...       \n",
    "    We call vectorization the general process of turning a collection of text documents into numerical \n",
    "        feature vectors. This specific strategy (tokenization, counting and normalization) is called \n",
    "        the Bag of Words or “Bag of n-grams” representation. Documents are described by word occurrences \n",
    "        while completely ignoring the relative position information of the words in the document.\n",
    "    '''\n",
    "    from sklearn.feature_extraction.text import CountVectorizer\n",
    "    \n",
    "    # Like usual we may need to cross validate this to determine the optimal represenation\n",
    "    # Cross validation link: https://scikit-learn.org/stable/auto_examples/model_selection/grid_search_text_feature_extraction.html#sphx-glr-auto-examples-model-selection-grid-search-text-feature-extraction-py\n",
    "    # max_features = ?\n",
    "    # ngram_range = ?\n",
    "    # fit_transform: Learn the vocabulary dictionary and return document-term matrix.\n",
    "    # EDIT: He has results in his paper about choosing good parameters for ngrams\n",
    "\n",
    "    vectorizer = CountVectorizer(ngram_range=(1, 2), min_df=3)\n",
    "    document_term_matrix = vectorizer.fit_transform(clean_data).toarray()\n",
    "    return document_term_matrix\n",
    "\n",
    "# Conduct vectorization to all data including train (original data) and test (additional data)\n",
    "## If not, dimension of train and testing data would not match => unable to conduct classification\n",
    "\n",
    "train_data_length = len(clean_data)\n",
    "clean_data_all = clean_data + clean_data_additional\n",
    "X_dataset = text_to_num(clean_data_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Dimension reduction\n",
    "Current status:\n",
    "\n",
    "No dimension reduction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# None by default.\n",
    "# When we add this, we'll do it off the X matrix here.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Training/Testing split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X train Shape: (4632, 9280)\n",
      "X original Shape: (1158, 9280)\n",
      "X additional Shape: (1041, 9280)\n",
      "y train shape(4632,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "\n",
    "# Should we do PCA on this? X is (5791, 8330)....\n",
    "# from sklearn.decomposition import PCA\n",
    "# n_components=250\n",
    "# pca = PCA(n_components=n_components) \n",
    "# X_reduced = pca.fit_transform(X)\n",
    "\n",
    "#  We are trying to see :\n",
    "###  when training 80% of original data, how well we estimate new dataset compared to 20% of the same dataset\n",
    "\n",
    "X_train = X_dataset[:train_data_length]\n",
    "y_train = data[\"Sentiment\"]\n",
    "y_train = y_train.replace(-1, 0)\n",
    "\n",
    "X_additional = X_dataset[train_data_length:]\n",
    "y_additional = data_additional[\"Sentiment\"]\n",
    "y_additional = y_additional.replace(-1, 0)\n",
    "\n",
    "alpha = 0.2  # percentage of additional data in the training set\n",
    "X_o_train, X_o_test, y_o_train, y_o_test = train_test_split(X_train, y_train, \n",
    "                                                            train_size = int(train_data_length*0.8*(1-alpha)),\n",
    "                                                           test_size = int(train_data_length*0.2),\n",
    "                                                           random_state=2021)\n",
    "add_len = len(y_additional)\n",
    "X_h_train, X_h_test, y_h_train, y_h_test = train_test_split(X_additional, y_additional,\n",
    "                                                           train_size = int(train_data_length*0.8*alpha),\n",
    "                                                           random_state=2021)\n",
    "\n",
    "X_train = np.vstack([X_o_train, X_h_train])\n",
    "y_train = np.concatenate([y_o_train, y_h_train])\n",
    "X_original = X_o_test\n",
    "y_original = y_o_test\n",
    "X_additional = X_h_test\n",
    "y_additional = y_h_test\n",
    "\n",
    "\n",
    "#X_train, X_original, y_train, y_original = train_test_split(X_train, y_train, test_size=0.2, random_state=2021)\n",
    "print(\"X train Shape: {}\".format(X_train.shape))\n",
    "print(\"X original Shape: {}\".format(X_original.shape))\n",
    "print(\"X additional Shape: {}\".format(X_additional.shape))\n",
    "print(f\"y train shape{y_train.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3706, 9280)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_o_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mixed data split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Model list definition:\n",
    "Current status: Multinomial NB, Logistic Regression, SVM, Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "models_to_try = []\n",
    "\n",
    "# Multinomial Naive Bayes\n",
    "models_to_try.append((\"MultinomialNB\",MultinomialNB()))\n",
    "\n",
    "# Gaussian Naive Bayes\n",
    "# Fitting gaussing naive bayes (like in class) instead\n",
    "# models_to_try.append((\"GaussianNB\", GaussianNB()))\n",
    "\n",
    "# Logistic Regression\n",
    "models_to_try.append((\"LogisticReg\", LogisticRegression()))\n",
    "\n",
    "# Support Vector Machine\n",
    "models_to_try.append((\"SVC\", SVC()))\n",
    "# models_to_try.append((\"SVC\", SVC(probability=True))) # Need this to use .predict_proba()\n",
    "\n",
    "# Random Forest\n",
    "models_to_try.append((\"RandomForest\", RandomForestClassifier()))\n",
    "\n",
    "# Multilayer Perceptron \n",
    "# Not going to fit a multilayer perceptron, here's XGB instead\n",
    "#models_to_try.append((\"XGB\", XGBClassifier()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Original ]\n",
      "MultinomialNB Accuracy: 0.7841105354058722\n",
      "MultinomialNB AUC: 0.8471120053053627\n",
      "MultinomialNB MCC: 0.5381197041620264\n",
      "[ Additional ]\n",
      "MultinomialNB Accuracy: 0.8318924111431316\n",
      "MultinomialNB AUC: 0.8888251380535331\n",
      "MultinomialNB MCC: 0.6013900517116358\n",
      "[ Original ]\n",
      "LogisticReg Accuracy: 0.7884283246977547\n",
      "LogisticReg AUC: 0.8541730073653556\n",
      "LogisticReg MCC: 0.5378997051545973\n",
      "[ Additional ]\n",
      "LogisticReg Accuracy: 0.8491834774255523\n",
      "LogisticReg AUC: 0.909326527382083\n",
      "LogisticReg MCC: 0.6265886816719821\n",
      "[ Original ]\n",
      "SVC Accuracy: 0.7728842832469776\n",
      "SVC MCC: 0.49588283950593653\n",
      "[ Additional ]\n",
      "SVC Accuracy: 0.7848222862632085\n",
      "SVC MCC: 0.4461195698357654\n",
      "[ Original ]\n",
      "RandomForest Accuracy: 0.7962003454231433\n",
      "RandomForest AUC: 0.85350983702669\n",
      "RandomForest MCC: 0.5597978451184612\n",
      "[ Additional ]\n",
      "RandomForest Accuracy: 0.8626320845341018\n",
      "RandomForest AUC: 0.8858354437058141\n",
      "RandomForest MCC: 0.6607263046152583\n"
     ]
    }
   ],
   "source": [
    "aucs = []\n",
    "mccs = []\n",
    "mcrs = []\n",
    "model_names = []\n",
    "\n",
    "aucs_add = []\n",
    "mccs_add = []\n",
    "mcrs_add = []\n",
    "model_names_add = []\n",
    "\n",
    "from sklearn.metrics import  roc_auc_score\n",
    "def prediction_results(models_to_try, X_train, X_original, X_additional, y_train, y_original, y_additional):\n",
    "    '''\n",
    "    Input:\n",
    "        models_to_try: a list of tuples (\"Name as a string\", object)\n",
    "        Data as usual\n",
    "        X, y : train / original / additional\n",
    "    Ouput:\n",
    "        Prints the accuracy and returns a dictionary to create a confusion matrix\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    def predict(classifier, X_test, y_test, name, confused_dict, model_names, aucs, mccs, mcrs) :\n",
    "        '''\n",
    "        Input :\n",
    "            classifiers, dataset\n",
    "            \n",
    "        Trys to find name, model_names, aucs, mccs, mcrs of each original and additional dataset\n",
    "        '''\n",
    "        preds = classifier.predict(X_test)\n",
    "        print(\"{} Accuracy: {}\".format(name, accuracy_score(y_test, preds)))\n",
    "        \n",
    "        if name != \"SVC\":\n",
    "            probs = classifier.predict_proba(X_test)[:, 1]\n",
    "            print(\"{} AUC: {}\".format(name, roc_auc_score(y_test, probs)))\n",
    "            aucs.append(roc_auc_score(y_test, probs))\n",
    "            \n",
    "        tn, fp, fn, tp = confusion_matrix(y_test, preds).ravel()\n",
    "        \n",
    "        MCC = (tp*tn - fp*fn)/np.sqrt((tp+fp)*(tp+fn)*(tn+fp)*(tn+fn))\n",
    "        print(\"{} MCC: {}\".format(name, MCC))\n",
    "        confused_dict[name] = [tn, fp, fn, tp]\n",
    "         \n",
    "        model_names.append(name)\n",
    "        mccs.append(MCC)\n",
    "        mcrs.append(accuracy_score(y_test, preds))\n",
    "        \n",
    "    confused_dict=dict()\n",
    "    confused_dict_add=dict()\n",
    "    for name, classifier in models_to_try:\n",
    "        # train \n",
    "        classifier.fit(X_train, y_train)\n",
    "\n",
    "        # predict on original data\n",
    "        print(\"[ Original ]\")\n",
    "        predict(classifier, X_original, y_original, name, confused_dict, model_names, aucs, mccs, mcrs)\n",
    "        \n",
    "        # predict on additional data\n",
    "        print(\"[ Additional ]\")\n",
    "        predict(classifier, X_additional, y_additional, name, confused_dict_add, model_names_add, aucs_add, mccs_add, mcrs_add)\n",
    "        \n",
    "    return confused_dict, confused_dict_add\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "confused_dict, confused_dict_add = prediction_results(models_to_try, X_train, X_original, X_additional, y_train, y_original, y_additional)\n",
    "\n",
    "def dict_to_output(confused_dict):\n",
    "    for key, value in confused_dict.items():\n",
    "        print(\"{} Confusion Matrix\".format(key))\n",
    "        print(pd.DataFrame({\"True Y=1\":[value[3],value[2]],\"True Y=0\":[value[1],value[0]]},index=[\"Guess Y=1\",\"Guess Y=0\"]))\n",
    "        print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Original Data ] \n",
      "\n",
      "MultinomialNB Confusion Matrix\n",
      "           True Y=1  True Y=0\n",
      "Guess Y=1       602       121\n",
      "Guess Y=0       129       306\n",
      "\n",
      "\n",
      "LogisticReg Confusion Matrix\n",
      "           True Y=1  True Y=0\n",
      "Guess Y=1       629       143\n",
      "Guess Y=0       102       284\n",
      "\n",
      "\n",
      "SVC Confusion Matrix\n",
      "           True Y=1  True Y=0\n",
      "Guess Y=1       664       196\n",
      "Guess Y=0        67       231\n",
      "\n",
      "\n",
      "RandomForest Confusion Matrix\n",
      "           True Y=1  True Y=0\n",
      "Guess Y=1       619       124\n",
      "Guess Y=0       112       303\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"[ Original Data ] \\n\")\n",
    "dict_to_output(confused_dict)\n",
    "\n",
    "df = pd.DataFrame()\n",
    "df['Misclassification'] = mcrs\n",
    "df['MCC'] = mccs\n",
    "df.index = model_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Additional Data ] \n",
      "\n",
      "MultinomialNB Confusion Matrix\n",
      "           True Y=1  True Y=0\n",
      "Guess Y=1       639        85\n",
      "Guess Y=0        90       227\n",
      "\n",
      "\n",
      "LogisticReg Confusion Matrix\n",
      "           True Y=1  True Y=0\n",
      "Guess Y=1       680       108\n",
      "Guess Y=0        49       204\n",
      "\n",
      "\n",
      "SVC Confusion Matrix\n",
      "           True Y=1  True Y=0\n",
      "Guess Y=1       712       207\n",
      "Guess Y=0        17       105\n",
      "\n",
      "\n",
      "RandomForest Confusion Matrix\n",
      "           True Y=1  True Y=0\n",
      "Guess Y=1       706       120\n",
      "Guess Y=0        23       192\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"[ Additional Data ] \\n\")\n",
    "dict_to_output(confused_dict_add)\n",
    "\n",
    "df1 = pd.DataFrame()\n",
    "df1['Misclassification'] = mcrs_add\n",
    "df1['MCC'] = mccs_add\n",
    "df1.index = model_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Misclassification</th>\n",
       "      <th>MCC</th>\n",
       "      <th>dataType</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MultinomialNB</th>\n",
       "      <td>0.784111</td>\n",
       "      <td>0.538120</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogisticReg</th>\n",
       "      <td>0.788428</td>\n",
       "      <td>0.537900</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVC</th>\n",
       "      <td>0.772884</td>\n",
       "      <td>0.495883</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForest</th>\n",
       "      <td>0.796200</td>\n",
       "      <td>0.559798</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Misclassification       MCC  dataType\n",
       "MultinomialNB           0.784111  0.538120  original\n",
       "LogisticReg             0.788428  0.537900  original\n",
       "SVC                     0.772884  0.495883  original\n",
       "RandomForest            0.796200  0.559798  original"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"dataType\"] = \"original\"\n",
    "df.to_csv(\"result/original_data_results_mix0.2.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Misclassification</th>\n",
       "      <th>MCC</th>\n",
       "      <th>dataType</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MultinomialNB</th>\n",
       "      <td>0.831892</td>\n",
       "      <td>0.601390</td>\n",
       "      <td>additional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogisticReg</th>\n",
       "      <td>0.849183</td>\n",
       "      <td>0.626589</td>\n",
       "      <td>additional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVC</th>\n",
       "      <td>0.784822</td>\n",
       "      <td>0.446120</td>\n",
       "      <td>additional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForest</th>\n",
       "      <td>0.862632</td>\n",
       "      <td>0.660726</td>\n",
       "      <td>additional</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Misclassification       MCC    dataType\n",
       "MultinomialNB           0.831892  0.601390  additional\n",
       "LogisticReg             0.849183  0.626589  additional\n",
       "SVC                     0.784822  0.446120  additional\n",
       "RandomForest            0.862632  0.660726  additional"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1[\"dataType\"] = \"additional\"\n",
    "df1.to_csv(\"result/additional_data_results_mix0.2.csv\")\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
